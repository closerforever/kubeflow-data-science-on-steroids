{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "A crucial task for every machine learning approach is exploring the data and understanding the problem you want to solve.\n",
    "Additionally you may want to make sure if there is invalid data and exclude it so it doesn't distort your accuracy and so on. \n",
    "Besides that, especially for deep learning approaches, the equalization of sample categories can play a important role \n",
    "when it comes to model performance. Let's try to tackle such an exploration task for a typical classification problem.\n",
    "Our data consists of vehicle identification numbers (VIN) which are somehow similar to IMAI numbers of mobile phones. \n",
    "A few samples can be found in the pandas DataFrame below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vin</th>\n",
       "      <th>GENERATIONNO</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>MAKENAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61327</th>\n",
       "      <td>TMBJG9NP5H7046274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superb (2015 - )</td>\n",
       "      <td>Skoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80458</th>\n",
       "      <td>TMBJG9NP3J7514167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superb (2015 - )</td>\n",
       "      <td>Skoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48955</th>\n",
       "      <td>VSSZZZ5FZH6508003</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ateca (2016 - )</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36398</th>\n",
       "      <td>TMBJG9NP6H7022792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superb (2015 - )</td>\n",
       "      <td>Skoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93449</th>\n",
       "      <td>WVWZZZAUZJW097552</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Golf (2017 - )</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98441</th>\n",
       "      <td>VSSZZZ5FZJ6530538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ateca (2016 - )</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77324</th>\n",
       "      <td>VSSZZZ5FZJ6500548</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ateca (2016 - )</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41076</th>\n",
       "      <td>TMBJG9NP8H7040050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superb (2015 - )</td>\n",
       "      <td>Skoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60757</th>\n",
       "      <td>VSSZZZ5FZH6543964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ateca (2016 - )</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31893</th>\n",
       "      <td>TMBJG9NP2H7500660</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superb (2015 - )</td>\n",
       "      <td>Skoda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Vin  GENERATIONNO       DESCRIPTION    MAKENAME\n",
       "61327  TMBJG9NP5H7046274           0.0  Superb (2015 - )       Skoda\n",
       "80458  TMBJG9NP3J7514167           0.0  Superb (2015 - )       Skoda\n",
       "48955  VSSZZZ5FZH6508003           1.0   Ateca (2016 - )        SEAT\n",
       "36398  TMBJG9NP6H7022792           0.0  Superb (2015 - )       Skoda\n",
       "93449  WVWZZZAUZJW097552           2.0    Golf (2017 - )  Volkswagen\n",
       "98441  VSSZZZ5FZJ6530538           1.0   Ateca (2016 - )        SEAT\n",
       "77324  VSSZZZ5FZJ6500548           1.0   Ateca (2016 - )        SEAT\n",
       "41076  TMBJG9NP8H7040050           0.0  Superb (2015 - )       Skoda\n",
       "60757  VSSZZZ5FZH6543964           1.0   Ateca (2016 - )        SEAT\n",
       "31893  TMBJG9NP2H7500660           0.0  Superb (2015 - )       Skoda"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dill\n",
    "with open(\"dataframe.dill\", \"rb\") as fp:\n",
    "    dataframe = dill.load(fp)\n",
    "\n",
    "dataframe.sample(frac=1).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data contains four different vehicle types namely \"Skoda\", \"Volkswagen\", \"Peugot\" and \"SEAT\". Additionally a \n",
    "description containing their model and the first year they got into production are supplied. Looking at this were \n",
    "little snippet we should notice three things: \n",
    "- every Vin contains 17 characters\n",
    "- every vehicle type has been tagged with a generation number\n",
    "- identical models seem to have very similar Vins\n",
    "\n",
    "The similarity in the Vin structures is a result of how information is encoded within a single Vin. \n",
    "Such encoded data may be: \n",
    "- the place where the vehicle has been crafted\n",
    "- the vehicles origin country\n",
    "- first year of the models production\n",
    "- ...\n",
    "\n",
    "As there is many facturer and country related information we should generally be capable of distinguishing between\n",
    "different models from looking at their Vin. A typical application for this might be a garage where an automatical \n",
    "deduction of vehicle informations from their Vin can save quite a lot of time. But before building a model to \n",
    "help us do this task let's have a little check if our above assumptions work out. \n",
    "First let's look if there is any Vin not containing 17 characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe[dataframe.Vin.apply(lambda x: len(x) < 17)].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! There is no Vin shorter than 17 characters, so our first assumption (at least from what we can see within this data)\n",
    "is proved. Now lets check if the generation numbers always refer to the exact same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vin</th>\n",
       "      <th>GENERATIONNO</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>MAKENAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>TMBJF73T4F9023304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Superb (2015 - )</td>\n",
       "      <td>Skoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>VF38D9HD8FL009350</td>\n",
       "      <td>3.0</td>\n",
       "      <td>508 (2014 - )</td>\n",
       "      <td>Peugeot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6812</th>\n",
       "      <td>VSSZZZ5FZH6517864</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ateca (2016 - )</td>\n",
       "      <td>SEAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25056</th>\n",
       "      <td>WVWZZZAUZHP309003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Golf (2017 - )</td>\n",
       "      <td>Volkswagen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Vin  GENERATIONNO       DESCRIPTION    MAKENAME\n",
       "888    TMBJF73T4F9023304           0.0  Superb (2015 - )       Skoda\n",
       "6389   VF38D9HD8FL009350           3.0     508 (2014 - )     Peugeot\n",
       "6812   VSSZZZ5FZH6517864           1.0   Ateca (2016 - )        SEAT\n",
       "25056  WVWZZZAUZHP309003           2.0    Golf (2017 - )  Volkswagen"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.drop_duplicates(['MAKENAME', 'DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one entry for each generation number thus we can directly use those as labels later, Neat!\n",
    "For our last assumption, for not diving to deep into details, let's check an obvious pattern: the \"SEAT\" \n",
    "numbers containing \"VSS\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_vss = dataframe[dataframe.MAKENAME == \"SEAT\"].Vin.apply(lambda x: \"VSS\" not in x)\n",
    "dataframe[(dataframe.MAKENAME == \"SEAT\") & (non_vss)].empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems true to be as well. As a final step let's check for duplicates before we can create an actual dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe[dataframe.duplicated([\"Vin\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! There was plenty of them. Gladly we eliminate them before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop_duplicates(\"Vin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our main step would be creating the actual dataset. For that purpose the Vins will be binarized and equalized folds will be created. \n",
    "Sklearns [Stratified K-Fold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html) and \n",
    "[Label Binarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html) are the best bet for this.\n",
    "As this still requires quite a lot of effort this work has been done and the dataset is stored to a folder called *dataset*.\n",
    "Note that the encoded data has been stored to images as it can be interpreted as such after encoding and it will be easier\n",
    "to import it to various frameworks data way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Munging\n",
    "After exploring the data we got a glimpse of an idea of how our data is structured, \n",
    "but a few important steps still need to be done. Those include: \n",
    "- creating folded sets for later cross validating our model and\n",
    "- bringing the data to a format useable for training \n",
    "\n",
    "While for the sake of easy demonstration cross validation will not be done within \n",
    "this very simple example, let's have a look on how to absolve especially the second step \n",
    "in a resource friendly manner. The fastai package, as well as pytorch/pytorchbearer/istio etc. \n",
    "give a convenience class for that purpose. That way we even avoid RAM shortage while training \n",
    "(as the ressources will be loaded chunk by chunk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (3040 items)\n",
       "x: ImageList\n",
       "Image (3, 17, 33),Image (3, 17, 33),Image (3, 17, 33),Image (3, 17, 33),Image (3, 17, 33)\n",
       "y: CategoryList\n",
       "3,3,3,3,3\n",
       "Path: dataset;\n",
       "\n",
       "Valid: LabelList (760 items)\n",
       "x: ImageList\n",
       "Image (3, 17, 33),Image (3, 17, 33),Image (3, 17, 33),Image (3, 17, 33),Image (3, 17, 33)\n",
       "y: CategoryList\n",
       "3,3,3,3,3\n",
       "Path: dataset;\n",
       "\n",
       "Test: None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.vision import ImageDataBunch\n",
    "dataset = ImageDataBunch.from_folder(\"dataset\", train=\"training\", valid=\"test\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned before the data has been preprocessed. Let's see how the first folds class sample amount are distributed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f03e9fa1128>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "_, training_counts = np.unique(dataset.train_ds.y.items, return_counts=True)\n",
    "_, test_counts = np.unique(dataset.valid_ds.y.items, return_counts=True)\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "ax = plt.bar([0, 1, 2, 3], height=training_counts, label=\"training set\")\n",
    "plt.bar([0, 1, 2, 3], height=test_counts, label=\"validation set\")\n",
    "plt.xticks([0, 1, 2, 3], [\"Skoda\", \"SEAT\", \"VW\", \"Peugeot\"])\n",
    "plt.subplots_adjust()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is around 760 samples for each class in the test set and 190 in the validation set respectively. \n",
    "Thats satisfying for a classification task. We can procede to training a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Process\n",
    "Now that the data has been brought to a format we can work with let's setup a model \n",
    "to learn the representation. We will use the powerful fastai learning approach in order to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.043314</td>\n",
       "      <td>10.907436</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>11.012269</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001582</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "res18_learner = cnn_learner(dataset, models.resnet18,  pretrained=False, metrics=accuracy)\n",
    "res18_learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a better comparisson on the models performance a few other popular architectures may\n",
    "be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.103828</td>\n",
       "      <td>1.249534</td>\n",
       "      <td>0.493421</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.084349</td>\n",
       "      <td>3.159742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.029539</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.011040</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004240</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.065466</td>\n",
       "      <td>3.280815</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>4.128419</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.006384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squeeze_learner = cnn_learner(dataset, models.squeezenet1_1, pretrained=False, metrics=accuracy)\n",
    "squeeze_learner.fit_one_cycle(5)\n",
    "res34_learner = cnn_learner(dataset, models.resnet34, pretrained=False, metrics=accuracy)\n",
    "res34_learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another very popular trick to increase performance is to use a transfer-learning with pretrained models.\n",
    "Again fastai enables us to do so as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.149541</td>\n",
       "      <td>10.459501</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.041723</td>\n",
       "      <td>5.034722</td>\n",
       "      <td>0.493421</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.014572</td>\n",
       "      <td>0.022158</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>0.015032</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002130</td>\n",
       "      <td>0.015129</td>\n",
       "      <td>0.998684</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/squeezenet1_1-f364aa15.pth\" to /home/mbu93/.cache/torch/checkpoints/squeezenet1_1-f364aa15.pth\n",
      "100%|██████████| 4.74M/4.74M [00:01<00:00, 4.02MB/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.222412</td>\n",
       "      <td>5.343445</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.021871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.173812</td>\n",
       "      <td>8.878108</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.048493</td>\n",
       "      <td>12.441313</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.017236</td>\n",
       "      <td>0.170833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.006428</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002454</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res18_learner_pre = cnn_learner(dataset, models.resnet18, pretrained=True, metrics=accuracy)\n",
    "res18_learner_pre.fit_one_cycle(5)\n",
    "squeeze_learner_pre = cnn_learner(dataset, models.squeezenet1_1, pretrained=True, metrics=accuracy)\n",
    "squeeze_learner_pre.fit_one_cycle(5)\n",
    "res34_learner_pre = cnn_learner(dataset, models.resnet34, pretrained=True, metrics=accuracy)\n",
    "res34_learner_pre.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Performance & Deployment\n",
    "Finally we are capable of selecting a final model for deployment. Typically this can be \n",
    "done by comparing the performance of the used models. In real world applications additionally\n",
    "some steps for cross validating and serving the application would be taken which will be skipped\n",
    "here to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.), tensor(1.), tensor(1.), tensor(1.), tensor(0.9987), tensor(1.)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learners = [squeeze_learner, res18_learner, res34_learner, \n",
    "            squeeze_learner_pre, res18_learner_pre, res34_learner_pre]\n",
    "\n",
    "accuracys = [accuracy(*x.get_preds()) for x in learners]\n",
    "accuracys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Squeezenet did the best job, practically it would be selected for deployment. To be even more sure\n",
    "we might want to have a final check on its confusion matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = squeeze_learner_pre.interpret()\n",
    "interp.plot_confusion_matrix(figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Pipelines for reproducing the training process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "After we have successfully build and selected a model we are ready to automate the training process.\n",
    "For that purpose KubeFlow Pipelines can be used. There are 3 ways of defining a pipeline:\n",
    "- pushing a training script to a docker image and execute it directly\n",
    "- using Google Cloud Storage for compiling python functions \n",
    "- writing lightweight components directly in python\n",
    "While the last option has the downside of very few options to pass data and the inherent \n",
    "condition to store temporary results, we will still use it because of its ease of implementation. \n",
    "Let's first of all define our python code for training etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_data_loader() -> str:\n",
    "    from fastai.vision import ImageDataBunch\n",
    "    import dill\n",
    "    import codecs\n",
    "    bunch = ImageDataBunch.from_folder(\n",
    "        \"test/images\", train=\"training\", valid=\"test\",\n",
    "        size=112)\n",
    "    return codecs.encode(dill.dumps(bunch), \"base64\").decode()\n",
    "\n",
    "\n",
    "def fit_squeezenet(loader: str, storage: str, pretrained: bool = False) -> str:\n",
    "    import dill\n",
    "    from fastai.vision import cnn_learner, accuracy, models\n",
    "    import codecs\n",
    "    name: str = \"squeezenet.model\"\n",
    "    loader = dill.loads(codecs.decode(loader.encode(), \"base64\"))\n",
    "    learner = cnn_learner(\n",
    "        loader, models.squeezenet1_0, pretrained=False, metrics=accuracy,\n",
    "        silent=False, add_time=True)\n",
    "    learner.fit_one_cycle(1)\n",
    "\n",
    "    outpath = storage + \"/\" + name\n",
    "    with open(outpath, \"wb\") as fp:\n",
    "        dill.dump(learner, fp)\n",
    "\n",
    "    return outpath\n",
    "\n",
    "def fit_resnet18(loader: str, storage: str, pretrained: bool = False) -> str:\n",
    "    import dill\n",
    "    from fastai.vision import cnn_learner, accuracy, models\n",
    "    import codecs\n",
    "    name = \"res18.model\"\n",
    "    loader = dill.loads(codecs.decode(loader.encode(), \"base64\"))\n",
    "    learner = cnn_learner(\n",
    "        loader, models.resnet18, pretrained=False, metrics=accuracy)\n",
    "    learner.fit_one_cycle(1)\n",
    "\n",
    "    outpath = storage + \"/\" + name\n",
    "    with open(outpath, \"wb\") as fp:\n",
    "        dill.dump(learner, fp)\n",
    "\n",
    "    return outpath\n",
    "\n",
    "\n",
    "def fit_resnet(loader: str, storage: str, pretrained: bool = False) -> str:\n",
    "    import dill\n",
    "    from fastai.vision import cnn_learner, accuracy, models\n",
    "    import codecs\n",
    "    name = \"resnet.model\"\n",
    "    loader = dill.loads(codecs.decode(loader.encode(), \"base64\"))\n",
    "\n",
    "    learner = cnn_learner(\n",
    "        loader, models.resnet34, pretrained=False, metrics=accuracy)\n",
    "    learner.fit_one_cycle(1)\n",
    "\n",
    "    outpath = storage + \"/\" + name\n",
    "    with open(outpath, \"wb\") as fp:\n",
    "        dill.dump(learner, fp)\n",
    "\n",
    "    return outpath\n",
    "\n",
    "\n",
    "def get_accuracy(learner: str) -> float:\n",
    "    from fastai.vision import accuracy\n",
    "    import dill\n",
    "\n",
    "    with open(learner, 'rb') as fp:\n",
    "        learner = dill.load(fp)\n",
    "\n",
    "    return float(accuracy(*learner.get_preds()).numpy())\n",
    "\n",
    "\n",
    "def get_confusion(learner: str) -> str:\n",
    "    from fastai.vision import ClassificationInterpretation\n",
    "    import dill\n",
    "\n",
    "    with open(learner, 'rb') as fp:\n",
    "        learner = dill.load(fp)\n",
    "\n",
    "    interpreter = ClassificationInterpretation.from_learner(learner)\n",
    "    return str(interpreter.confusion_matrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline definition\n",
    "For defining the pipeline we will leverage the kfp packages capabilitys of compiling\n",
    "pipeline components. First of all we will set a few path definitions etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import json\n",
    "import os.path as path\n",
    "import sys\n",
    "from functools import wraps\n",
    "from typing import Dict\n",
    "\n",
    "import kfp.dsl as dsl\n",
    "import numpy as np\n",
    "from kfp import compiler\n",
    "from kfp.compiler import Compiler\n",
    "from kfp.components import func_to_container_op as py_convert\n",
    "from kfp.dsl import ContainerOp, ExitHandler, pipeline\n",
    "from kubernetes import client as k8s\n",
    "\n",
    "OUT_DIR = '/something'\n",
    "METADATA_FILE = 'mlpipeline-ui-metadata.json'\n",
    "METRICS_FILE = 'mlpipeline-metrics.json'\n",
    "METADATA_FILE_PATH = path.join(OUT_DIR, METADATA_FILE)\n",
    "METRICS_FILE_PATH = path.join(OUT_DIR, METRICS_FILE)\n",
    "SQUEEZE_FILE = \"squeezenet.model\"\n",
    "RES18_FILE = \"res18.model\"\n",
    "RESNET_FILE = \"resnet.model\"\n",
    "SQUEEZE_FILE_PATH = path.join(OUT_DIR, SQUEEZE_FILE)\n",
    "RES18_FILE_PATH = path.join(OUT_DIR, RES18_FILE)\n",
    "RESNET_FILE_PATH = path.join(OUT_DIR, RESNET_FILE)\n",
    "DEPLOYED_MODEL = SQUEEZE_FILE\n",
    "BASE_IMAGE = 'mbu93/kubeflow:latest'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, as prototype demonstrating how deployment could be triggered, a component triggering a \n",
    "direct action within a container will be described as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markdown_metadata(result: str) -> str:\n",
    "    return json.dumps({\n",
    "        'outputs': [{\n",
    "            'type': 'markdown',\n",
    "            'source': 'The result: %s' % result,\n",
    "            'storage': 'inline',\n",
    "        }]\n",
    "    })\n",
    "\n",
    "def default_artifact_path() -> Dict[str, str]:\n",
    "    return {\n",
    "        path.splitext(METADATA_FILE)[0]: METADATA_FILE_PATH,\n",
    "        path.splitext(METRICS_FILE)[0]: METRICS_FILE_PATH,\n",
    "    }\n",
    "\n",
    "def demo_op(name: str, metadata=markdown_metadata,\n",
    "            is_exit_handler=False) -> ContainerOp:\n",
    "    op = ContainerOp(name=name,\n",
    "                     image=BASE_IMAGE,\n",
    "                     command=['sh', '-c'],\n",
    "                     arguments=[\n",
    "                         'echo \"Running step $0\" && echo \"$1\" > $2',\n",
    "                         name,\n",
    "                         metadata(name),\n",
    "                         METADATA_FILE_PATH,\n",
    "                     ],\n",
    "                     is_exit_handler=is_exit_handler)\n",
    "    op.add_volume(\n",
    "        k8s.V1Volume(name='volume',\n",
    "                     host_path=k8s.V1HostPathVolumeSource(path='/data/out')))\\\n",
    "        .add_volume_mount(k8s.V1VolumeMount(name='volume', mount_path=OUT_DIR))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to store and load data processed in earlier stages we will also define a wrapper which mounts \n",
    "a persistent volume to every lightweight components later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storage_op(func, *args):\n",
    "    op = py_convert(func, base_image=BASE_IMAGE)(*args)\n",
    "    op.add_volume(k8s.V1Volume(name='volume',\n",
    "                               host_path=k8s.V1HostPathVolumeSource(path='/data/out')))\\\n",
    "      .add_volume_mount(k8s.V1VolumeMount(name='volume', mount_path=OUT_DIR))\n",
    "    return op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as final step we define the dedicated pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name='FastAI Training Pipeline', description='T')\n",
    "def training_pipeline(pretrained: bool = False):\n",
    "    deploy = demo_op('deploy', is_exit_handler=True)\n",
    "    with ExitHandler(deploy):\n",
    "        # setup the data loader\n",
    "        setup_data = py_convert(setup_data_loader, base_image=BASE_IMAGE)()\n",
    "\n",
    "        # fit all networks\n",
    "        fit_squeeze = storage_op(fit_squeezenet, setup_data.output, OUT_DIR, pretrained)\n",
    "        fit_res18 = storage_op(fit_resnet18, setup_data.output, OUT_DIR, pretrained)\n",
    "        fit_res = storage_op(fit_resnet, setup_data.output, OUT_DIR, pretrained)\n",
    "        fit_squeeze.default_artifact_paths = {path.splitext(SQUEEZE_FILE)[0]: SQUEEZE_FILE_PATH}\n",
    "        fit_res18.default_artifact_paths = {path.splitext(RES18_FILE)[0]: RES18_FILE_PATH}\n",
    "        fit_res.default_artifact_paths = {path.splitext(RESNET_FILE)[0]: RESNET_FILE_PATH}\n",
    "\n",
    "        # get the network accuracys\n",
    "        squeeze_acc = storage_op(get_accuracy, fit_squeeze.output)\n",
    "        res18_acc = storage_op(get_accuracy, fit_res18.output)\n",
    "        res_acc = storage_op(get_accuracy, fit_res.output)\n",
    "\n",
    "        # get the confusion matrices\n",
    "        squeeze_confusion = storage_op(get_confusion, fit_squeeze.output)\n",
    "        res18_confusion = storage_op(get_confusion, fit_res18.output)\n",
    "        res_confusion = storage_op(get_confusion, fit_res.output)\n",
    "\n",
    "        # save the best model for later deployment\n",
    "        models = np.array([SQUEEZE_FILE_PATH, RES18_FILE_PATH, RESNET_FILE_PATH])\n",
    "        best = np.argmax([squeeze_acc.output, res18_acc.output, res_acc.output])\n",
    "        globals()['DEPLOYED_MODEL'] = models[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the pipeline\n",
    "The pipeline described above will now be compiled using the kfg package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_func = training_pipeline\n",
    "pipeline_filename = pipeline_func.__name__ + '.pipeline.yaml'\n",
    "Compiler().compile(pipeline_func, pipeline_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline deployment\n",
    "Now that everything is setup and all steps are descibed the pipeline can be run on the cluster.\n",
    "For that purpose we will first create a prototype experiment to check if everything works fine. As the pretrained models parameters need to be downloaded at each container run, we will not use transfer learning for the tests to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/kfp/_client.py:157: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  return yaml.load(f)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Run link <a href=\"/pipeline/#/runs/details/81a37c1e-c84d-11e9-a325-0800270c2570\" target=\"_blank\" >here</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arguments = {'pretrained': 'False'}\n",
    "\n",
    "#Get or create an experiment and submit a pipeline run\n",
    "import kfp\n",
    "client = kfp.Client()\n",
    "\n",
    "try:\n",
    "    experiment = client.create_experiment(\"Prototyping\")\n",
    "except Exception:\n",
    "    experiment = client.get_experiment(experiment_name=\"Prototyping\")\n",
    "    \n",
    "#Submit a pipeline run\n",
    "run_name = pipeline_func.__name__ + ' test_run'\n",
    "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
